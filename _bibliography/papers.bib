@inproceedings{cha2025feature,
    title = "Feature Learning as a Virtual Covariance Learning",
    author= "Cha, Taehun  and
      Lee, Donghun",
    booktitle = "OPT 2025: Optimization for Machine Learning",
    year = "2025",
    website = "https://openreview.net/forum?id=hvw5FJoaWB",
    pdf = "2025/Neurips2025_Workshop_Paper.pdf",
    abstract = "Feature learning is central to the success of neural networks but remains poorly understood. Recent work proposed the Neural Feature Ansatz, which highlights alignment between learned features and $\nabla_x f$, but does not explicitly explain why and how feature learning dynamics occur. To address this, we introduce a novel concept, **virtual update**, a stochastic gradient descent (SGD) step applied to inputs and hidden states rather than parameters, i.e., $x - \gamma \nabla_x \mathcal{L}$ and $h - \gamma \nabla_h \mathcal{L}$. We theoretically show that SGD aligns network weights with the covariance structure of the virtual update. This does not result in disagreement with an actual update, as the actually updated input does not deviate far from the virtually updated input. Building on this insight, we propose the **virtual covariance learning** algorithm, which directly obtains the weight matrix that achieves the desired covariance structure. This algorithm efficiently learns effective weights within one or two epochs--whereas SGD requires $10$–$20$ epochs--with low variance and no overfitting."
}

@inproceedings{smith2025evaluating,
    title= "Evaluating Generalization Capabilities of {LLM}-Based Agents in Mixed-Motive Scenarios Using Concordia",
    author= "Chandler Smith and Marwa Abdulhai and Manfred Diaz and Marko Tesic and Rakshit Trivedi and Sasha Vezhnevets and Lewis Hammond and Jesse Clifton and Minsuk Chang and Edgar A. Du{\'e}{\~n}ez-Guzm{\'a}n and John P Agapiou and Jayd Matyas and Danny Karmon and Beining Zhang and Jim Dilkes and Akash Kundu and Jord Nguyen and Emanuel Tewolde and Jebish Purbey and Ram Mohan Rao Kadiyala and Siddhant Gupta and Aliaksei Korshuk and Buyantuev Alexander and Ilya Makarov and Gang Zhao and Rolando Fernandez and Zhihan Wang and Caroline Wang and Jiaxun Cui and Lingyun Xiao and Di Yang Shi and Yoonchang Sung and Arrasy Rahman and Peter Stone and Yipeng Kang and Hyeonggeun Yun and Ananya Ananya and Taehun Cha and Zhiqiang Wu and Elizaveta Tennant and Olivia Macmillan-Scott and Marta Emili Garc{\'\i}a Segura and Diana Riazi and Fuyang Cui and Sriram Ganapathi Subramanian and Toryn Q. Klassen and Nico Schiavone and Mogtaba Alim and Sheila A. McIlraith and Manuel Sebastian Rios Beltran and Oswaldo Pe{\~n}a and Carlos Saith Rodriguez Rojas and Manuela Chacon-Chamorro and Ruben Manrique and Luis Felipe Giraldo and Nicanor Quijano and Yiding Wang and Yuxuan Chen and Fangwei Zhong and Mengmeng Wang and Wenming Tu and Zhaowei Zhang and Ziang Chen and Zixia Jia and Xue Feng and Zilong Zheng and Chichen Lin and Weijian Fan and Chenao Liu and Sneheel Sarangi and Ziyan Wang and Shuqing Shi and Yali Du and Avinaash Anand Kulandaivel and Yang Liu and Wu Ruiyang and Chetan Talele and 陆孙嘉 and Gema Parre{\~n}o Piqueras and Shamika Dhuri and Bain McHale and Tim Baarslag and Dylan Hadfield-Menell and Natasha Jaques and Jose Hernandez-Orallo and Joel Z Leibo",
    booktitle= "The Thirty-ninth Annual Conference on Neural Information Processing Systems Datasets and Benchmarks Track",
    year= "2025",
    website = "https://openreview.net/forum?id=yG4Fj0voJZ",
    abstract = "Large language model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. This work introduces an approach to measuring human-appropriate cooperative intelligence, emphasizing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement."
}

@inproceedings{cha2025emergent,
    title= "Emergent Linear Separability of Unseen Data Points in High-dimensional Last-Layer Feature Space",
    author= "Cha, Taehun  and
      Lee, Donghun",
    booktitle= "High-dimensional Learning Dynamics 2025",
    year= "2025",
    website= "https://openreview.net/forum?id=ZycrmjxehT",
    pdf = "2025/ICML2025_Workshop_Paper.pdf",
    poster = "2025/ICML2025_Workshop_Poster.pdf",
    abstract = "In this work, we investigate the emergence of linear separability for unseen data points in the high-dimensional last-layer feature space of deep neural networks. Through empirical analysis, we observe that, after training, in-distribution and out-of-distribution samples become linearly separable in the last-layer feature space when the hidden dimension is sufficiently high—even in regimes where the input data itself is not. We leverage these observations for the task of uncertainty quantification. By connecting our findings to classical support vector machine margin theory, we theoretically show that the separating hyperplane exhibits a higher weight norm when facing in-distribution data points. This work highlights linear separability as a fundamental and analyzable property of trained deep neural networks' representations, offering a geometric perspective on the practical uncertainty quantification task in neural networks."
  }

@inproceedings{cha-lee-2025-active,
    title = "ABC3: Active Bayesian Causal Inference with Cohn Criteria in Randomized Experiments",
    author = "Cha, Taehun  and
      Lee, Donghun",
    booktitle = "The 39th Annual AAAI Conference on Artificial Intelligence",
    month = feb,
    year = "2025",
    website="https://arxiv.org/abs/2412.11104/",
    pdf = "2025/AAAI2025_Paper.pdf",
    slides = "2025/AAAI2025_PPT.pdf",
    poster = "2025/AAAI2025_Poster.pdf",
    abstract = "In causal inference, a randomized experiment is a de facto method to overcome various theoretical issues in observational study. However, the experimental design requires expensive costs, so an efficient experimental design is necessary. We propose ABC3, a Bayesian active learning policy for causal inference. We show a policy minimizing an estimation error on conditional average treatment effect is equivalent to minimizing an integrated posterior variance, similar to Cohn criteria. We theoretically prove ABC3 also minimizes an imbalance between the treatment and control groups and the type 1 error probability. Imbalance-minimizing characteristic is especially notable as several works have emphasized the importance of achieving balance. Through extensive experiments on real-world data sets, ABC3 achieves the highest efficiency, while empirically showing the theoretical results hold."
}

@inproceedings{cha-lee-2024-pre,
    title = "Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts",
    author = "Cha, Taehun  and
      Lee, Donghun",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    website="https://aclanthology.org/2024.findings-emnlp.738/",
    pdf = "2024/EMNLP2024_Paper.pdf",
    slides = "2024/EMNLP2024_PPT.pdf",
    poster = "2024/EMNLP2024_Poster.pdf",
    doi = "10.18653/v1/2024.findings-emnlp.738",
    pages = "12630--12639",
    abstract = "In this work, we show the pre-trained language models return distinguishable generation probability and uncertainty distribution to unfaithfully hallucinated texts, regardless of their size and structure. By examining 24 models on 6 data sets, we find out that 88-98{\%} of cases return statistically significantly distinguishable generation probability and uncertainty distributions. Using this general phenomenon, we showcase a hallucination-reducing training algorithm. Our algorithm outperforms other baselines by achieving higher faithfulness metrics while maintaining sound general text quality measures.",
}

@inproceedings{cha-lee-2024-evaluating,
    title = "Evaluating Extrapolation Ability of Large Language Model in Chemical Domain",
    author = "Cha, Taehun  and
      Lee, Donghun",
    editor = "Edwards, Carl  and
      Wang, Qingyun  and
      Li, Manling  and
      Zhao, Lawrence  and
      Hope, Tom  and
      Ji, Heng",
    booktitle = "Proceedings of the 1st Workshop on Language + Molecules (L+M 2024)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    website = "https://aclanthology.org/2024.langmol-1.4",
    pdf = "2024/ACL2024_Workshop_Paper.pdf",
    poster = "2024/ACL2024_Workshop_Poster.pdf",
    doi = "10.18653/v1/2024.langmol-1.4",
    pages = "28--33",
    abstract = "Solving a problem outside the training space, i.e. extrapolation, has been a long problem in the machine learning community. The current success of large language models demonstrates the LLM{'}s extrapolation ability to several unseen tasks. In line with these works, we evaluate the LLM{''}s extrapolation ability in the chemical domain. We construct a data set measuring the material properties of epoxy polymers depending on various raw materials and curing processes. LLM should predict the material property when novel raw material is introduced utilizing its chemical knowledge. Through experiments, LLM tends to choose the right direction of adjustment but fails to determine the exact degree, resulting in poor MAE on some properties. But LLM can successfully adjust the degree with only a one-shot example. The results show that LLM can extrapolate to new unseen material utilizing its chemical knowledge learned through massive pre-training.",
}

@inproceedings{cha-lee-2024-sentencelda,
    title = "{S}entence{LDA}: Discriminative and Robust Document Representation with Sentence Level Topic Model",
    author = "Cha, Taehun  and
      Lee, Donghun",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    website = "https://aclanthology.org/2024.eacl-long.31",
    pdf = "2024/EACL2024_Paper.pdf",
    slides = "2024/EACL2024_PPT.pdf",
    pages = "521--538",
    abstract = "A subtle difference in context results in totally different nuances even for lexically identical words. On the other hand, two words can convey similar meanings given a homogeneous context. As a result, considering only word spelling information is not sufficient to obtain quality text representation. We propose SentenceLDA, a sentence-level topic model. We combine modern SentenceBERT and classical LDA to extend the semantic unit from word to sentence. By extending the semantic unit, we verify that SentenceLDA returns more discriminative document representation than other topic models, while maintaining LDA{'}s elegant probabilistic interpretability. We also verify the robustness of SentenceLDA by comparing the inference results on original and paraphrased texts. Additionally, we implement one possible application of SentenceLDA on corpus-level key opinion mining by applying SentenceLDA on an argumentative corpus, DebateSum.",
}

@inproceedings{cha-etal-2022-noun,
    title = "Noun-{MWP}: Math Word Problems Meet Noun Answers",
    author = "Cha, Taehun  and
      Jung, Jaeheun  and
      Lee, Donghun",
    editor = "Calzolari, Nicoletta  and
      Huang, Chu-Ren  and
      Kim, Hansaem  and
      Pustejovsky, James  and
      Wanner, Leo  and
      Choi, Key-Sun  and
      Ryu, Pum-Mo  and
      Chen, Hsin-Hsi  and
      Donatelli, Lucia  and
      Ji, Heng  and
      Kurohashi, Sadao  and
      Paggio, Patrizia  and
      Xue, Nianwen  and
      Kim, Seokhwan  and
      Hahm, Younggyun  and
      He, Zhong  and
      Lee, Tony Kyungil  and
      Santus, Enrico  and
      Bond, Francis  and
      Na, Seung-Hoon",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    website = "https://aclanthology.org/2022.coling-1.338",
    pdf = "2022/COLING2022_Paper.pdf",
    slides = "2022/COLING2022_PPT.pdf",
    poster = "2022/COLING2022_Poster.pdf",
    pages = "3847--3857",
    abstract = "We introduce a new type of problems for math word problem (MWP) solvers, named Noun-MWPs, whose answer is a non-numerical string containing a noun from the problem text. We present a novel method to empower existing MWP solvers to handle Noun-MWPs, and apply the method on Expression-Pointer Transformer (EPT). Our model, N-EPT, solves Noun-MWPs significantly better than other models, and at the same time, solves conventional MWPs as well. Solving Noun-MWPs may lead to bridging MWP solvers and traditional question-answering NLP models.",
}
